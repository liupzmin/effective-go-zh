# Concurrency

## Share by communicating

*Concurrent programming is a large topic and there is space only for some Go-specific highlights here.*

并发编程所涉过于庞大，此处仅就 Go 的特殊之处论之。

*Concurrent programming in many environments is made difficult by the subtleties required to implement correct access to shared variables. Go encourages a different approach in which shared values are passed around on channels and, in fact, never actively shared by separate threads of execution. Only one goroutine has access to the value at any given time. Data races cannot occur, by design. To encourage this way of thinking we have reduced it to a slogan:*

很多环境下的并发编程因一些微妙之处变得很困难，问题在于你需要实现对共享变量的正确访问。Go 鼓励一种不同的方式：将需要共享的值通过 channel 来传递。事实上，不要一味地在不同的执行流之间共享数据。在任意给定的时刻有且仅有一个 goroutine 可以访问该值。Go channel 在设计上就消除了这种数据竞争。为鼓励这种思维方式，我们将其归纳为一条 slogan：

> Do not communicate by sharing memory; instead, share memory by communicating.
>
> 不要通过共享内存来通信，而是通过通信来共享内存。

*This approach can be taken too far. Reference counts may be best done by putting a mutex around an integer variable, for instance. But as a high-level approach, using channels to control access makes it easier to write clear, correct programs.*

有时这种方式可能会显得有些过头。比如对于计数器最好的的访问方式是为整型变量添加一个 mutex。然而，在高层次上将，使用 channel 来控制数据的访问会使编写清晰，正确的程序变得简单。

*One way to think about this model is to consider a typical single-threaded program running on one CPU. It has no need for synchronization primitives. Now run another such instance; it too needs no synchronization. Now let those two communicate; if the communication is the synchronizer, there's still no need for other synchronization. Unix pipelines, for example, fit this model perfectly. Although Go's approach to concurrency originates in Hoare's Communicating Sequential Processes (CSP), it can also be seen as a type-safe generalization of Unix pipes.*

为便于理解此并发模型，考虑一个跑在单核 CPU 上典型的单线程程序。它是不需要同步源语的。现在再运行一个此程序的实例，也是不需要同步的。现在让它们两个通信，如果通信本身就是一个同步装置，那么仍然不需要其它形式的同步。例如，Unix 管道就与此模型完美契合。尽管 Go 的并发模型源自于 Hoare 的 CSP 模型，但它依然可以看做是类型安全的 Unix 管道的泛化。

## Goroutines

*They're called **goroutines** because the existing terms—threads, coroutines, processes, and so on—convey inaccurate connotations. A goroutine has a simple model: it is a function executing concurrently with other goroutines in the same address space. It is lightweight, costing little more than the allocation of stack space. And the stacks start small, so they are cheap, and grow by allocating (and freeing) heap storage as required.*

Go 的并发单位被称作 **goroutines**，是因为现存的术语——线程，协程，进程等都无法传达其隐含的意义。goroutine 的模型很简单：它是一个与其它的 groutine 并发运行于同一地址空间的函数。groutine 是轻量的，成本略高于堆栈空间的分配。而且 goroutine 的初始堆栈很小，因此非常廉价，并能从 heap 上按需增长。

*Goroutines are multiplexed onto multiple OS threads so if one should block, such as while waiting for I/O, others continue to run. Their design hides many of the complexities of thread creation and management.*

Goroutine 在多个操作系统线程上多路复用，因此如果一个被阻塞（例如 I/O等待），则其它的 goroutine 可继续调度到其它操作系统上运行。Goroutine 的设计隐藏了很多线程创建和管理的复杂性。

*Prefix a function or method call with the `go` keyword to run the call in a new goroutine. When the call completes, the goroutine exits, silently. (The effect is similar to the Unix shell's `&` notation for running a command in the background.)*

在函数或者方法前使用 `go` 关键字即可开启一个新的 goroutine。当调用完成，goroutine 就会默默退出。（其效果类似于 Unlix shell 的 `&` 符号，它的作用是让一个命令在后台运行。）

```go
go list.Sort()  // run list.Sort concurrently; don't wait for it.
```

*A function literal can be handy in a goroutine invocation.*

函数的字面值可以出现在 goroutine 的调用中。

```go
func Announce(message string, delay time.Duration) {
    go func() {
        time.Sleep(delay)
        fmt.Println(message)
    }()  // Note the parentheses - must call the function.
}
```

*In Go, function literals are closures: the implementation makes sure the variables referred to by the function survive as long as they are active.*

在 Go 中，函数字面值是闭包的：这确保了被函数引用的变量在其活跃期间一直存活（意为有足够的生存期）。

*These examples aren't too practical because the functions have no way of signaling completion. For that, we need channels.*

这些例子不太实用，因为函数没有办法发出完成的信号。为此，我们需要 channel。

## Channels

*Like maps, channels are allocated with `make`, and the resulting value acts as a reference to an underlying data structure. If an optional integer parameter is provided, it sets the buffer size for the channel. The default is zero, for an unbuffered or synchronous channel.*

channel 和 map 一样使用 `make` 进行分配，其结果表现为一个对底层数据结构的引用。如果提供了可选的整数参数，将设置为channel 的 buffer 大小。其默认值是 0，即一个无缓冲的同步 channel。

```go
ci := make(chan int)            // unbuffered channel of integers
cj := make(chan int, 0)         // unbuffered channel of integers
cs := make(chan *os.File, 100)  // buffered channel of pointers to Files
```

*Unbuffered channels combine communication—the exchange of a value—with synchronization—guaranteeing that two calculations (goroutines) are in a known state.*

无缓冲的 channel 将通信所需的数据交换和同步整合在一起，确保两个 goroutine 的计算都处于已知状态。

*There are lots of nice idioms using channels. Here's one to get us started. In the previous section we launched a sort in the background. A channel can allow the launching goroutine to wait for the sort to complete.*

channel 有很多不错的地道用法。我们用其中一个来开始。前面章节我们在后台运行了一个排序函数，可以用 channel  使得父 goroutine 能够等待排序完成。

```go
c := make(chan int)  // Allocate a channel.
// Start the sort in a goroutine; when it completes, signal on the channel.
go func() {
    list.Sort()
    c <- 1  // Send a signal; value does not matter. 发送信号，值无关不紧要
}()
doSomethingForAWhile()
<-c   // Wait for sort to finish; discard sent value. // 等待排序完成，丢弃接收到的值
```

*Receivers always block until there is data to receive. If the channel is unbuffered, the sender blocks until the receiver has received the value. If the channel has a buffer, the sender blocks only until the value has been copied to the buffer; if the buffer is full, this means waiting until some receiver has retrieved a value.*

在收到数据之前接收者将一直阻塞。如果是无缓冲 channel，在接收者收到数据之前发送者将一直阻塞。如果是带缓冲的 channel ，发送者仅在数据被拷贝到缓冲区之前阻塞；如果缓冲区已满，这意味着发送者将阻塞至有接收者接收数据。

*A buffered channel can be used like a semaphore, for instance to limit throughput. In this example, incoming requests are passed to `handle`, which sends a value into the channel, processes the request, and then receives a value from the channel to ready the “semaphore” for the next consumer. The capacity of the channel buffer limits the number of simultaneous calls to `process`.*

缓冲 channel 可以像信号量一样使用，例如限制吞吐。下例中，入站请求被传送至 `handle`，`handle` 向 channel 发送一个值，之后处理请求，请求完成之后再从 channel 读取一个值来为下一个消费者准备好 “信号量”。缓冲 channel 的容量决定了 `process` 的并发数。

```go
var sem = make(chan int, MaxOutstanding)

func handle(r *Request) {
    sem <- 1    // Wait for active queue to drain.
    process(r)  // May take a long time.
    <-sem       // Done; enable next request to run.
}

func Serve(queue chan *Request) {
    for {
        req := <-queue
        go handle(req)  // Don't wait for handle to finish.
    }
}
```

*Once `MaxOutstanding` handlers are executing `process`, any more will block trying to send into the filled channel buffer, until one of the existing handlers finishes and receives from the buffer.*

一旦有 `MaxOutstanding` 个 handler 正在运行 `process`，后续的 `handler` 就会因向已被填满的 channel 发送数据而阻塞，直到其中一个运行完毕从缓冲区取走一个值为止。 

*This design has a problem, though: `Serve` creates a new goroutine for every incoming request, even though only `MaxOutstanding` of them can run at any moment. As a result, the program can consume unlimited resources if the requests come in too fast. We can address that deficiency by changing `Serve` to gate the creation of the goroutines. Here's an obvious solution, but beware it has a bug we'll fix subsequently:*

这样设计有个问题：尽管同一时刻只能有 `MaxOutstanding` 个可以运行，但 `Serve` 会为每一个入栈请求都创建一个 goroutine 。结果就是：如果请求进入过快，程序对资源的消耗就会失去控制。我们可以修改 `Serve` 来把控 goroutine 的创建，从而解决问题。下面是个浅显的解决方案，请当心其中的 bug，我们随后就会修复它：

```go
func Serve(queue chan *Request) {
    for req := range queue {
        sem <- 1
        go func() {
            process(req) // Buggy; see explanation below. bug, 请看下面的解释
            <-sem
        }()
    }
}
```

*The bug is that in a Go `for` loop, the loop variable is reused for each iteration, so the `req` variable is shared across all goroutines. That's not what we want. We need to make sure that `req` is unique for each goroutine. Here's one way to do that, passing the value of `req` as an argument to the closure in the goroutine:*

这个 bug 出现在 Go 的 for 循环中，循环变量在每次迭代中都会被重用，因此 `req` 变量是被所有的 goroutine 共享的。这并非我们本意，我们需要保证每个 goroutine 的 `req` 都是唯一的。下面是一种处理方式，在 goroutine 中将 `req` 作为参数传给闭包：

```go
func Serve(queue chan *Request) {
    for req := range queue {
        sem <- 1
        go func(req *Request) {
            process(req)
            <-sem
        }(req)
    }
}
```

*Compare this version with the previous to see the difference in how the closure is declared and run. Another solution is just to create a new variable with the same name, as in this example:*

比较一下这个版本与上一个，注意在闭包声明和运行上的不同。另一个解决方法就是创建一个同名变量，如下：

```go
func Serve(queue chan *Request) {
    for req := range queue {
        req := req // Create new instance of req for the goroutine. 创建一个新的 req
        sem <- 1
        go func() {
            process(req)
            <-sem
        }()
    }
}
```

*It may seem odd to write*

这样写或许看起来很怪：

```go
req := req
```

*but it's legal and idiomatic in Go to do this. You get a fresh version of the variable with the same name, deliberately shadowing the loop variable locally but unique to each goroutine.*

但在 Go 中这是合法且地道的做法。你用同样的名字得到一个新的变量，在循环中有意地遮蔽本地变量使得每个 goroutine 都有唯一的值。

*Going back to the general problem of writing the server, another approach that manages resources well is to start a fixed number of `handle` goroutines all reading from the request channel. The number of goroutines limits the number of simultaneous calls to `process`. This `Serve` function also accepts a channel on which it will be told to exit; after launching the goroutines it blocks receiving from that channel.*

回到编写 server 的问题上，另一种管理资源的方法是开启固定数量的 goroutine，让它们从请求 channel 中读取。goroutine 的数量限制了同时调用 `process`的数量。这个 `Serve` 还接收一个用于退出的 channel；启动完 goroutine 之后，阻塞于对该 channel 的读取上。

```go
func handle(queue chan *Request) {
    for r := range queue {
        process(r)
    }
}

func Serve(clientRequests chan *Request, quit chan bool) {
    // Start handlers
    for i := 0; i < MaxOutstanding; i++ {
        go handle(clientRequests)
    }
    <-quit  // Wait to be told to exit.
}
```

## Channels of channels

*One of the most important properties of Go is that a channel is a first-class value that can be allocated and passed around like any other. A common use of this property is to implement safe, parallel demultiplexing.*

channel 是第一公民，这是 Go 最重要的特性之一，它可以像任意其它类型值一样被分配和传递。该特性的一个常见用途是实现安全，并行的解复用（demultiplexing）。

*In the example in the previous section, `handle` was an idealized handler for a request but we didn't define the type it was handling. If that type includes a channel on which to reply, each client can provide its own path for the answer. Here's a schematic definition of type `Request`.*

前面章节的例子中，`handle` 太过理想化，我们并没有定义要处理的 Request 类型。如果 Request 包含一个可用于回复的 channel， 那么每一个客户端都能为其回应提供自己的路径。以下为 Request 类型的大概定义。

```go
type Request struct {
    args        []int
    f           func([]int) int
    resultChan  chan int
}
```

*The client provides a function and its arguments, as well as a channel inside the request object on which to receive the answer.*

客户端提供了一个函数及其参数，此外在 Request 中还有个接收应答的 channel 。

```go
func sum(a []int) (s int) {
    for _, v := range a {
        s += v
    }
    return
}

request := &Request{[]int{3, 4, 5}, sum, make(chan int)}
// Send request
clientRequests <- request
// Wait for response.
fmt.Printf("answer: %d\n", <-request.resultChan)
```

*On the server side, the handler function is the only thing that changes.*

Server 端仅需修改处理函数：

```go
func handle(queue chan *Request) {
    for req := range queue {
        req.resultChan <- req.f(req.args)
    }
}
```

*There's clearly a lot more to do to make it realistic, but this code is a framework for a rate-limited, parallel, non-blocking RPC system, and there's not a mutex in sight.*

要想更加实用还有很多工作要做，但这些代码已经是一个具有限速、并行、非阻塞功能的 RPC 系统框架了，并且它没有使用互斥锁。
